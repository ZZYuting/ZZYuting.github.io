---
title: 决策树
layout: post
categories: 机器学习基础
excerpt: 
Tags: 机器学习基础
---

#### 决策树是一种典型的分类方法

#### 一、决策树是一种典型的分类方法	

首先对数据进行处理，利用归纳算法生成可读的规则和决策树，然后使用决策对新数据进行分析。

本质上决策树是通过一系列规则对数据进行分类的过程

决策树学习算法包括三部分：**特征选择、树的生成和树的剪枝**

常见的算法有**ID3、C4.5、CART**

特征选择的目的**在于选取对训练数据能够分类的特征**，特征选择的关键是准则，**常见的准则有：**

​	**信息增益（ID3）、信息增益比（C4.5）、基尼指数（CART）**

#### 二、决策树的优缺点：

优点

1、**推理过程容易理解，决策推理过程可以表示成If Then形式**

2、**决策树算法可以用于小数据集**

3、**决策树算法的时间复杂度较小、效率高**

缺点

1、**容易出现过拟 合**

2、在处理特征关联性比较强的数据时表现得不是太好 

3、对于各类别样本数量不一致的数据，在决策树当中，信息增益的结果偏向于那些具有更多数值的特征 

4、当类别太多时，错误可能就会增加的比较快

#### 三、决策树的生成和剪枝

生成：通常使用**信息增益最大、信息增益比最大或基尼指数最小**作为特征选择的准则，**从根节点开始，递归地产生决策树**。

剪枝：由于生成的**决策树存在过拟合**，需要剪枝简化决策树，**通常从已生成的树上减掉一些叶节点或者叶节点以上的子树，并将其父节点或根节点作为新的叶节点**，从而简化生成的决策树。 参考统计学习方法P67页图